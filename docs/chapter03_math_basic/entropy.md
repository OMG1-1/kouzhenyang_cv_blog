## 熵（entropy）

物理学上，是“混乱” 程度的度量。
系统越有序，熵值越低；系统越混乱或分散，熵值越高。
信息理论:

1. 当系统的有序状态一致时，数据越集中的地方熵值越小，数据越分散的地方熵值越大。
   1. 这是从信息的完整性上进行的描述。
2. 当数据量一致时，系统越有序，熵值越低；系统越混乱或者分散，熵值越高。
   1. 这是从信息的有序性上进行的描述。

若不确定性越大，则信息量越大，熵越大
若不确定性越小，则信息量越小，熵越小

### 定义

假如事件 A 的分类划分是$(A1,A2,...,An)$，每部分发生的概率是$(p1,p2,...,pn)$，那信息熵定义为公式如下：
$Ent(A) = - \sum_{k=1}^nP_klog_2p_k$
